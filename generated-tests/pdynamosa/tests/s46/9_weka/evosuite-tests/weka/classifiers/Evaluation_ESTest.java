/*
 * This file was automatically generated by EvoSuite
 * Sun Mar 24 11:25:26 GMT 2019
 */

package weka.classifiers;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.util.Random;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.mock.java.util.MockRandom;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;
import weka.attributeSelection.OneRAttributeEval;
import weka.attributeSelection.WrapperSubsetEval;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.Classifier;
import weka.classifiers.ConditionalDensityEstimator;
import weka.classifiers.CostMatrix;
import weka.classifiers.Evaluation;
import weka.classifiers.IntervalEstimator;
import weka.classifiers.Sourcable;
import weka.classifiers.functions.GaussianProcesses;
import weka.classifiers.functions.SGDText;
import weka.classifiers.functions.SimpleLinearRegression;
import weka.classifiers.functions.SimpleLogistic;
import weka.classifiers.functions.VotedPerceptron;
import weka.classifiers.functions.supportVector.PolyKernel;
import weka.classifiers.functions.supportVector.PrecomputedKernelMatrixKernel;
import weka.classifiers.lazy.IBk;
import weka.classifiers.lazy.LWL;
import weka.classifiers.meta.AdaBoostM1;
import weka.classifiers.meta.CostSensitiveClassifier;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.meta.LogitBoost;
import weka.classifiers.meta.MultiClassClassifier;
import weka.classifiers.meta.MultiClassClassifierUpdateable;
import weka.classifiers.meta.RegressionByDiscretization;
import weka.classifiers.meta.Vote;
import weka.classifiers.misc.InputMappedClassifier;
import weka.classifiers.misc.SerializedClassifier;
import weka.classifiers.rules.JRip;
import weka.classifiers.rules.PART;
import weka.classifiers.rules.ZeroR;
import weka.classifiers.trees.M5P;
import weka.classifiers.trees.RandomTree;
import weka.core.AbstractInstance;
import weka.core.BinarySparseInstance;
import weka.core.Capabilities;
import weka.core.CapabilitiesHandler;
import weka.core.DenseInstance;
import weka.core.FindWithCapabilities;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.SparseInstance;
import weka.core.TestInstances;
import weka.core.converters.ConverterUtils;
import weka.core.converters.TextDirectoryLoader;
import weka.core.neighboursearch.LinearNNSearch;
import weka.core.neighboursearch.balltrees.BallNode;
import weka.estimators.KernelEstimator;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class Evaluation_ESTest extends Evaluation_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test000()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      int[] intArray0 = new int[9];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1136903110, intArray0, (-1));
      assertEquals(9, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals(9, binarySparseInstance0.numValues());
      assertEquals(1.13690311E9, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(9, intArray0.length);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, binarySparseInstance0.numClasses());
      assertEquals(9, binarySparseInstance0.numValues());
      assertEquals(1.13690311E9, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[6];
      doubleArray0[1] = (double) (-726);
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(9, intArray0.length);
      assertEquals(6, doubleArray0.length);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertArrayEquals(new double[] {0.0, (-726.0), 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, binarySparseInstance0.numClasses());
      assertEquals(9, binarySparseInstance0.numValues());
      assertEquals(1.13690311E9, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.classIndex());
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(100.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1.13690311E9, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.13690311E9, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
  }

  @Test(timeout = 4000)
  public void test001()  throws Throwable  {
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      assertNotNull(findWithCapabilities0);
      assertEquals("", findWithCapabilities0.getFilename());
      
      Capabilities capabilities0 = findWithCapabilities0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[1];
      doubleArray0[0] = (-3782.4231312);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-3782.4231312), doubleArray0);
      assertEquals(1, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {(-3782.4231312)}, doubleArray0, 0.01);
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals((-3782.4231312), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test002()  throws Throwable  {
      ZeroR zeroR0 = new ZeroR();
      assertNotNull(zeroR0);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
      
      String string0 = Evaluation.wekaStaticWrapper(zeroR0, "\nSynopsis for weka.classifiers.rules.ZeroR:\n\nClass for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).");
      assertNotNull(string0);
      assertEquals("Class for building and using a 0-R classifier. Predicts the mean (for a numeric class) or the mode (for a nominal class).", zeroR0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", zeroR0.debugTipText());
      assertFalse(zeroR0.getDebug());
  }

  @Test(timeout = 4000)
  public void test003()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1);
      assertNotNull(binarySparseInstance0);
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(0.0, double0, 0.01);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.numInstances(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double1 = evaluation0.rootMeanPriorSquaredError();
      assertEquals(0.6125000005587935, double1, 0.01);
      assertNotEquals(double1, double0, 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.numInstances(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test004()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      
      double double0 = evaluation0.priorEntropy();
      assertEquals(0.0, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
  }

  @Test(timeout = 4000)
  public void test005()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(0.0, double0, 0.01);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(1.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double1 = evaluation0.pctIncorrect();
      assertEquals(0.0, double1, 0.01);
      assertEquals(double1, double0, 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(1.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test006()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      evaluation0.m_WithClass = 2005.24329;
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double double0 = evaluation0.pctCorrect();
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test007()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(0.0, double0, 0.01);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(-0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(-0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(-0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(-0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(-0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1.0), evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(-0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(-0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(-0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double1 = evaluation0.numInstances();
      assertEquals((-1.0), double1, 0.01);
      assertNotEquals(double1, double0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(-0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(-0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(-0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(-0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(-0.0, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1.0), evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(-0.0, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(-0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(-0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test008()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate(".bsi");
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = evaluation0.makeDistribution(1.0);
      assertEquals(2, doubleArray0.length);
      assertNotNull(doubleArray0);
      assertArrayEquals(new double[] {0.0, 1.0}, doubleArray0, 0.01);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test009()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[] doubleArray0 = evaluation0.makeDistribution(Double.NaN);
      assertEquals(0, doubleArray0.length);
      assertNotNull(doubleArray0);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
  }

  @Test(timeout = 4000)
  public void test010()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances1 = evaluation0.getHeader();
      assertFalse(instances1.equals((Object)instances0));
      assertNotNull(instances1);
      assertNotSame(instances0, instances1);
      assertNotSame(instances1, instances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0, instances1.classIndex());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertEquals(0, instances1.numInstances());
      assertEquals(1, instances1.numAttributes());
      assertEquals(0, instances1.size());
      assertEquals(0.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test011()  throws Throwable  {
      LogitBoost logitBoost0 = new LogitBoost();
      assertNotNull(logitBoost0);
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertFalse(logitBoost0.getUseResampling());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertFalse(logitBoost0.getDebug());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(10, logitBoost0.getNumIterations());
      
      String string0 = Evaluation.getGlobalInfo(logitBoost0);
      assertEquals("\nSynopsis for weka.classifiers.meta.LogitBoost:\n\nClass for performing additive logistic regression. \nThis class performs classification using a regression scheme as the base learner, and can handle multi-class problems.  For more information, see\n\nJ. Friedman, T. Hastie, R. Tibshirani (1998). Additive Logistic Regression: a Statistical View of Boosting. Stanford University.\n\nCan do efficient internal cross-validation to determine appropriate number of iterations.", string0);
      assertNotNull(string0);
      assertEquals((-1.7976931348623157E308), logitBoost0.getLikelihoodThreshold(), 0.01);
      assertFalse(logitBoost0.getUseResampling());
      assertEquals("The number of iterations to be performed.", logitBoost0.numIterationsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", logitBoost0.debugTipText());
      assertEquals("Number of folds for internal cross-validation (default 0 means no cross-validation is performed).", logitBoost0.numFoldsTipText());
      assertEquals(1.0, logitBoost0.getShrinkage(), 0.01);
      assertEquals("The random number seed to be used.", logitBoost0.seedTipText());
      assertEquals("Threshold on improvement in likelihood.", logitBoost0.likelihoodThresholdTipText());
      assertEquals("Number of runs for internal cross-validation.", logitBoost0.numRunsTipText());
      assertEquals("The base classifier to be used.", logitBoost0.classifierTipText());
      assertEquals("Shrinkage parameter (use small value like 0.1 to reduce overfitting).", logitBoost0.shrinkageTipText());
      assertEquals(100, logitBoost0.getWeightThreshold());
      assertEquals("Weight threshold for weight pruning (reduce to 90 for speeding up learning process).", logitBoost0.weightThresholdTipText());
      assertFalse(logitBoost0.getDebug());
      assertEquals(1, logitBoost0.getSeed());
      assertEquals(1, logitBoost0.getNumRuns());
      assertEquals(0, logitBoost0.getNumFolds());
      assertEquals("Whether resampling is used instead of reweighting.", logitBoost0.useResamplingTipText());
      assertEquals(10, logitBoost0.getNumIterations());
  }

  @Test(timeout = 4000)
  public void test012()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = evaluation0.getClassPriors();
      assertEquals(2, doubleArray0.length);
      assertNotNull(doubleArray0);
      assertArrayEquals(new double[] {12.0, 10.0}, doubleArray0, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test013()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[3];
      doubleArray0[0] = (double) 1;
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {1.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {1.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(1.0, double0, 0.01);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {1.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(-0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(163.26530597349944, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(-0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(1.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(-0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(-0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.errorRate(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals((-1.0), evaluation0.numInstances(), 0.01);
      assertEquals(-0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(163.26530597349944, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
  }

  @Test(timeout = 4000)
  public void test014()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[8];
      doubleArray0[0] = (double) (-2);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-850.072), doubleArray0);
      assertEquals(8, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {(-2.0), 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(8, binarySparseInstance0.numAttributes());
      assertEquals((-850.072), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(8, doubleArray0.length);
      assertArrayEquals(new double[] {(-2.0), 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(8, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals((-850.072), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals((-2.0), double0, 0.01);
      assertEquals(8, doubleArray0.length);
      assertArrayEquals(new double[] {(-2.0), 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals((-850.072), evaluation0.numInstances(), 0.01);
      assertEquals(-0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(2.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(2.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(326.5306119469989, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(2.0, evaluation0.errorRate(), 0.01);
      assertEquals(326.5306119469989, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(-0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(-0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(-0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(-0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(8, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals((-850.072), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
  }

  @Test(timeout = 4000)
  public void test015()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      evaluation0.m_WithClass = 0.02500000037252903;
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.02500000037252903, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      
      double double0 = evaluation0.errorRate();
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.02500000037252903, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test016()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(0, doubleArray0.length);
      assertNotNull(doubleArray0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
  }

  @Test(timeout = 4000)
  public void test017()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      evaluation0.m_WithClass = 2005.24329;
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double0 = evaluation0.SFMeanEntropyGain();
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test018()  throws Throwable  {
      KernelEstimator kernelEstimator0 = new KernelEstimator((-1.0));
      assertNotNull(kernelEstimator0);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      
      Capabilities capabilities0 = new Capabilities(kernelEstimator0);
      assertNotNull(capabilities0);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.KBRelativeInformation();
      assertEquals(0.0, double0, 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertFalse(kernelEstimator0.getDebug());
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test019()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      evaluation0.m_WithClass = 2005.24329;
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
      
      double double0 = evaluation0.KBMeanInformation();
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(2005.24329, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test020()  throws Throwable  {
      AdaBoostM1 adaBoostM1_0 = new AdaBoostM1();
      assertNotNull(adaBoostM1_0);
      assertEquals(1, adaBoostM1_0.getSeed());
      assertFalse(adaBoostM1_0.getUseResampling());
      assertEquals("If set to true, classifier may output additional info to the console.", adaBoostM1_0.debugTipText());
      assertFalse(adaBoostM1_0.getDebug());
      assertEquals(10, adaBoostM1_0.getNumIterations());
      assertEquals("The base classifier to be used.", adaBoostM1_0.classifierTipText());
      assertEquals("The number of iterations to be performed.", adaBoostM1_0.numIterationsTipText());
      assertEquals("The random number seed to be used.", adaBoostM1_0.seedTipText());
      assertEquals("Whether resampling is used instead of reweighting.", adaBoostM1_0.useResamplingTipText());
      assertEquals(100, adaBoostM1_0.getWeightThreshold());
      assertEquals("Weight threshold for weight pruning.", adaBoostM1_0.weightThresholdTipText());
      
      try { 
        Evaluation.wekaStaticWrapper(adaBoostM1_0, "");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No model built yet
         //
         verifyException("weka.classifiers.meta.AdaBoostM1", e);
      }
  }

  @Test(timeout = 4000)
  public void test021()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[9];
      SparseInstance sparseInstance0 = new SparseInstance((-2), doubleArray0);
      assertEquals(9, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals((-2.0), sparseInstance0.weight(), 0.01);
      assertEquals(9, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForPredictor(2, sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test022()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      assertNotNull(binarySparseInstance0);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(0, binarySparseInstance0.numAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForPredictor(269.92667, binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test023()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double[] doubleArray0 = new double[7];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      assertEquals(7, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(7, sparseInstance0.numAttributes());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForPredictor(0.0, sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test024()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, instances0.size());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, instances0.size());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(19);
      assertNotNull(binarySparseInstance0);
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(19, binarySparseInstance0.numAttributes());
      assertEquals(19, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForPredictor((-58.413325416785), binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test025()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(gaussianProcesses0, (Instance) null, (-2441.686005));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test026()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      
      double[] doubleArray0 = new double[3];
      SparseInstance sparseInstance0 = new SparseInstance(0, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(3, sparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(3, sparseInstance0.numAttributes());
      assertEquals(0.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(gaussianProcesses0, binarySparseInstance0, (-688.3));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test027()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      
      double[] doubleArray0 = new double[1];
      SparseInstance sparseInstance0 = new SparseInstance(625.0375995726677, doubleArray0);
      assertEquals(1, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertEquals(1, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(625.0375995726677, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance0);
      assertEquals(1, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertEquals(1, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(625.0375995726677, sparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(625.0375995726677, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(1, doubleArray0.length);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(625.0375995726677, sparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(625.0375995726677, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(gaussianProcesses0, binarySparseInstance0, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test028()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      int[] intArray0 = new int[8];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(497.0, intArray0, (-3223));
      assertEquals(8, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals((-3223), binarySparseInstance0.numAttributes());
      assertEquals(497.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(8, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator((IntervalEstimator) null, binarySparseInstance0, 14);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test029()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(3, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numClasses());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(2, binarySparseInstance0.classIndex());
      assertEquals(1, binarySparseInstance0.numClasses());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(regressionByDiscretization0, binarySparseInstance0, (-1));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  @Test(timeout = 4000)
  public void test030()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      int[] intArray0 = new int[1];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1724.6048394576117), intArray0, 3883);
      assertEquals(1, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0}, intArray0);
      assertEquals((-1724.6048394576117), binarySparseInstance0.weight(), 0.01);
      assertEquals(3883, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator((IntervalEstimator) null, binarySparseInstance0, 116);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test031()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      
      double[] doubleArray0 = new double[7];
      SparseInstance sparseInstance0 = new SparseInstance(429.398, doubleArray0);
      assertEquals(7, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(429.398, sparseInstance0.weight(), 0.01);
      assertEquals(7, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(gaussianProcesses0, sparseInstance0, (-283.45));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test032()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double[] doubleArray0 = new double[7];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      assertEquals(7, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(7, sparseInstance0.numAttributes());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(gaussianProcesses0, sparseInstance0, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test033()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(305.229258488, doubleArray0);
      assertEquals(0, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals(305.229258488, sparseInstance0.weight(), 0.01);
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(gaussianProcesses0, sparseInstance0, Double.NaN);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test034()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      assertNotNull(regressionByDiscretization0);
      assertEquals("The base classifier to be used.", regressionByDiscretization0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", regressionByDiscretization0.debugTipText());
      assertEquals("If set to true, equal-frequency binning will be used instead of equal-width binning.", regressionByDiscretization0.useEqualFrequencyTipText());
      assertEquals(10, regressionByDiscretization0.getNumBins());
      assertEquals("Whether to minimize absolute error.", regressionByDiscretization0.minimizeAbsoluteErrorTipText());
      assertEquals("The density estimator to use.", regressionByDiscretization0.estimatorTypeTipText());
      assertEquals("Whether to delete empty bins after discretization.", regressionByDiscretization0.deleteEmptyBinsTipText());
      assertFalse(regressionByDiscretization0.getMinimizeAbsoluteError());
      assertFalse(regressionByDiscretization0.getDeleteEmptyBins());
      assertFalse(regressionByDiscretization0.getUseEqualFrequency());
      assertFalse(regressionByDiscretization0.getDebug());
      assertEquals("Number of bins for discretization.", regressionByDiscretization0.numBinsTipText());
      assertEquals(1, RegressionByDiscretization.ESTIMATOR_KERNEL);
      assertEquals(0, RegressionByDiscretization.ESTIMATOR_HISTOGRAM);
      assertEquals(2, RegressionByDiscretization.ESTIMATOR_NORMAL);
      
      int[] intArray0 = new int[1];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), intArray0, (-2));
      assertEquals(1, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0}, intArray0);
      assertEquals((-1.0), binarySparseInstance0.weight(), 0.01);
      assertEquals((-2), binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(regressionByDiscretization0, binarySparseInstance0, 1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  @Test(timeout = 4000)
  public void test035()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[7];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-38.6), doubleArray0);
      assertEquals(7, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(7, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-38.6), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(7, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(7, binarySparseInstance0.numAttributes());
      assertEquals(1, binarySparseInstance0.classIndex());
      assertEquals(2, binarySparseInstance0.numClasses());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-38.6), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator((ConditionalDensityEstimator) null, binarySparseInstance0, 0.0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test036()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      
      double[] doubleArray0 = new double[8];
      int[] intArray0 = new int[8];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(186.25123802, intArray0, (-1984208500));
      assertEquals(8, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals((-1984208500), binarySparseInstance0.numAttributes());
      assertEquals(186.25123802, binarySparseInstance0.weight(), 0.01);
      assertEquals(8, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForClassifier(doubleArray0, binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test037()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(0);
      assertNotNull(binarySparseInstance0);
      assertEquals(0, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForClassifier(doubleArray0, binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test038()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double[] doubleArray0 = new double[6];
      int[] intArray0 = new int[7];
      SparseInstance sparseInstance0 = new SparseInstance(1399.557122, doubleArray0, intArray0, (-1));
      assertEquals(6, doubleArray0.length);
      assertEquals(7, intArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals(1399.557122, sparseInstance0.weight(), 0.01);
      assertEquals((-1), sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updatePriors(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test039()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      evaluation0.updateNumericScores((double[]) null, (double[]) null, Double.POSITIVE_INFINITY);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test040()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double[] doubleArray0 = new double[2];
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, 0.0);
      assertEquals(2, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0}, doubleArray0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  @Test(timeout = 4000)
  public void test041()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      double[] doubleArray0 = new double[0];
      evaluation0.updateNumericScores(doubleArray0, doubleArray0, (-1.0));
      assertEquals(0, doubleArray0.length);
      assertArrayEquals(new double[] {}, doubleArray0, 0.01);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test042()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      
      double[] doubleArray0 = new double[1];
      // Undeclared exception!
      try { 
        evaluation0.updateMargins(doubleArray0, 104, 0.0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 104
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test043()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[7];
      evaluation0.updateMargins(doubleArray0, 4, 1027.3574209813064);
      assertEquals(7, doubleArray0.length);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test044()  throws Throwable  {
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      
      PolyKernel polyKernel0 = (PolyKernel)gaussianProcesses0.getKernel();
      assertNotNull(polyKernel0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      
      Capabilities capabilities0 = new Capabilities(polyKernel0);
      assertNotNull(capabilities0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.classIndex());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.trueNegativeRate(0);
      assertEquals(0.0, double0, 0.01);
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("The exponent value.", polyKernel0.exponentTipText());
      assertEquals(1.0, polyKernel0.getExponent(), 0.01);
      assertEquals(0, polyKernel0.numEvals());
      assertFalse(polyKernel0.getChecksTurnedOff());
      assertEquals("Whether to use lower-order terms.", polyKernel0.useLowerOrderTipText());
      assertFalse(polyKernel0.getUseLowerOrder());
      assertEquals("Turns time-consuming checks off - use with caution.", polyKernel0.checksTurnedOffTipText());
      assertEquals(250007, polyKernel0.getCacheSize());
      assertEquals(0, polyKernel0.numCacheHits());
      assertEquals("The size of the cache (a prime number), 0 for full cache and -1 to turn it off.", polyKernel0.cacheSizeTipText());
      assertFalse(polyKernel0.getDebug());
      assertEquals("The polynomial kernel : K(x, y) = <x, y>^p or K(x, y) = (<x, y>+1)^p", polyKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", polyKernel0.debugTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test045()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      String string0 = evaluation0.toSummaryString(true);
      assertEquals("=== Summary ===\n\nTotal Number of Instances                0     \n", string0);
      assertNotNull(string0);
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test046()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      
      String string0 = evaluation0.toSummaryString("", true);
      assertEquals("\nTotal Number of Instances                0     \n", string0);
      assertNotNull(string0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test047()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      String string0 = evaluation0.toMatrixString((String) null);
      assertEquals("null\n   <-- classified as\n", string0);
      assertNotNull(string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
  }

  @Test(timeout = 4000)
  public void test048()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      
      String string0 = evaluation0.toClassDetailsString((String) null);
      assertEquals("null\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      assertNotNull(string0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test049()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      evaluation0.setPriors(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test050()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      double double0 = evaluation0.precision(0);
      assertEquals(0.0, double0, 0.01);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test051()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      double double0 = evaluation0.precision((-352));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.size());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test052()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      
      double double0 = evaluation0.numTrueNegatives((-1616));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
  }

  @Test(timeout = 4000)
  public void test053()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double double0 = evaluation0.numFalsePositives((-200));
      assertEquals(0.0, double0, 0.01);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
  }

  @Test(timeout = 4000)
  public void test054()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      char[] charArray0 = new char[4];
      String string0 = evaluation0.num2ShortID(0, charArray0, 1266);
      assertEquals(4, charArray0.length);
      assertNotNull(string0);
      assertArrayEquals(new char[] {'\u0000', '\u0000', '\u0000', '\u0000'}, charArray0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test055()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      char[] charArray0 = new char[1];
      String string0 = evaluation0.num2ShortID((-2248), charArray0, 108);
      assertEquals("                                                                                                           \u0000", string0);
      assertEquals(1, charArray0.length);
      assertNotNull(string0);
      assertArrayEquals(new char[] {'\u0000'}, charArray0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test056()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, instances0.size());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, instances0.size());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.matthewsCorrelationCoefficient(0);
      assertEquals(0.0, double0, 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, instances0.size());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test057()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      double double0 = evaluation0.matthewsCorrelationCoefficient((-3813));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
  }

  @Test(timeout = 4000)
  public void test058()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.makeDistribution(0.0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test059()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.makeDistribution((-4442.065));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -4442
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test060()  throws Throwable  {
      Evaluation.main((String[]) null);
  }

  @Test(timeout = 4000)
  public void test061()  throws Throwable  {
      try { 
        Evaluation.handleCostOption(".arff", (-1));
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test062()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      
      double double0 = evaluation0.falseNegativeRate(0);
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
  }

  @Test(timeout = 4000)
  public void test063()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      
      double double0 = evaluation0.falseNegativeRate((-1112));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test064()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double double0 = evaluation0.fMeasure((-2612));
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  @Test(timeout = 4000)
  public void test065()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(3.0, (int[]) null, (-1461032992));
      assertNotNull(binarySparseInstance0);
      assertEquals(3.0, binarySparseInstance0.weight(), 0.01);
      assertEquals((-1461032992), binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double[] doubleArray0 = new double[9];
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test066()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      assertNotNull(serializedClassifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      assertFalse(serializedClassifier0.getDebug());
      
      int[] intArray0 = new int[0];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1442.34969491232, intArray0, 475);
      assertEquals(0, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {}, intArray0);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1442.34969491232, binarySparseInstance0.weight(), 0.01);
      assertEquals(475, binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) serializedClassifier0, (Instance) binarySparseInstance0, false);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test067()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      
      M5P m5P0 = new M5P();
      assertNotNull(m5P0);
      assertEquals("If set to true, classifier may output additional info to the console.", m5P0.debugTipText());
      assertFalse(m5P0.getUnpruned());
      assertFalse(m5P0.getUseUnsmoothed());
      assertEquals("Whether to save instance data at each node in the tree for visualization purposes.", m5P0.saveInstancesTipText());
      assertEquals("Whether to use unsmoothed predictions.", m5P0.useUnsmoothedTipText());
      assertEquals("The minimum number of instances to allow at a leaf node.", m5P0.minNumInstancesTipText());
      assertFalse(m5P0.getBuildRegressionTree());
      assertFalse(m5P0.getSaveInstances());
      assertEquals(1, m5P0.graphType());
      assertEquals("Whether to generate rules (decision list) rather than a tree.", m5P0.generateRulesTipText());
      assertFalse(m5P0.getDebug());
      assertEquals("Whether unpruned tree/rules are to be generated.", m5P0.unprunedTipText());
      assertEquals(4.0, m5P0.getMinNumInstances(), 0.01);
      assertEquals("Whether to generate a regression tree/rule instead of a model tree/rule.", m5P0.buildRegressionTreeTipText());
      
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) m5P0, (Instance) null, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test068()  throws Throwable  {
      FindWithCapabilities findWithCapabilities0 = new FindWithCapabilities();
      assertNotNull(findWithCapabilities0);
      assertEquals("", findWithCapabilities0.getFilename());
      
      Capabilities capabilities0 = findWithCapabilities0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", findWithCapabilities0.getFilename());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[1];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-3782.4231312), doubleArray0);
      assertEquals(1, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals((-3782.4231312), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      binarySparseInstance0.setDataset(instances0);
      assertEquals(1, doubleArray0.length);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertEquals("", findWithCapabilities0.getFilename());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, binarySparseInstance0.classIndex());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(2, binarySparseInstance0.numClasses());
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals((-3782.4231312), binarySparseInstance0.weight(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test069()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      DenseInstance denseInstance0 = new DenseInstance(7);
      assertNotNull(denseInstance0);
      assertEquals(7, denseInstance0.numValues());
      assertEquals(7, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      SparseInstance sparseInstance0 = new SparseInstance(denseInstance0);
      assertNotNull(sparseInstance0);
      assertEquals(7, denseInstance0.numValues());
      assertEquals(7, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(7, sparseInstance0.numAttributes());
      assertEquals(7, sparseInstance0.numValues());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((double[]) null, (Instance) sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test070()  throws Throwable  {
      MultiClassClassifier multiClassClassifier0 = new MultiClassClassifier();
      assertNotNull(multiClassClassifier0);
      assertEquals(2.0, multiClassClassifier0.getRandomWidthFactor(), 0.01);
      assertEquals("Sets the method to use for transforming the multi-class problem into several 2-class ones.", multiClassClassifier0.methodTipText());
      assertEquals("The base classifier to be used.", multiClassClassifier0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multiClassClassifier0.debugTipText());
      assertEquals(1, multiClassClassifier0.getSeed());
      assertEquals("The random number seed to be used.", multiClassClassifier0.seedTipText());
      assertFalse(multiClassClassifier0.getUsePairwiseCoupling());
      assertEquals("Use pairwise coupling (only has an effect for 1-against-1).", multiClassClassifier0.usePairwiseCouplingTipText());
      assertEquals("A metaclassifier for handling multi-class datasets with 2-class classifiers. This classifier is also capable of applying error correcting output codes for increased accuracy.", multiClassClassifier0.globalInfo());
      assertFalse(multiClassClassifier0.getDebug());
      assertEquals("Sets the width multiplier when using random codes. The number of codes generated will be thus number multiplied by the number of classes.", multiClassClassifier0.randomWidthFactorTipText());
      assertEquals(3, MultiClassClassifier.METHOD_1_AGAINST_1);
      assertEquals(1, MultiClassClassifier.METHOD_ERROR_RANDOM);
      assertEquals(2, MultiClassClassifier.METHOD_ERROR_EXHAUSTIVE);
      assertEquals(0, MultiClassClassifier.METHOD_1_AGAINST_ALL);
      
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      int[] intArray0 = new int[9];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1438.428734), intArray0, 2);
      assertEquals(9, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals(9, binarySparseInstance0.numValues());
      assertEquals((-1438.428734), binarySparseInstance0.weight(), 0.01);
      assertEquals(2, binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) multiClassClassifier0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test071()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      SerializedClassifier serializedClassifier0 = new SerializedClassifier();
      assertNotNull(serializedClassifier0);
      assertFalse(serializedClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", serializedClassifier0.debugTipText());
      assertEquals("The serialized classifier model to use for predictions.", serializedClassifier0.modelFileTipText());
      assertEquals("A wrapper around a serialized classifier model. This classifier loads a serialized models and uses it to make predictions.\n\nWarning: since the serialized model doesn't get changed, cross-validation cannot bet used with this classifier.", serializedClassifier0.globalInfo());
      
      double[] doubleArray0 = new double[3];
      int[] intArray0 = new int[8];
      SparseInstance sparseInstance0 = new SparseInstance((-2441.686005), doubleArray0, intArray0, (-963));
      assertEquals(3, doubleArray0.length);
      assertEquals(8, intArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals((-963), sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals((-2441.686005), sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      assertEquals(3, doubleArray0.length);
      assertEquals(8, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals((-963), sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals((-2441.686005), sparseInstance0.weight(), 0.01);
      assertEquals((-963), binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals((-2441.686005), binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) serializedClassifier0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test072()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[3];
      int[] intArray0 = new int[5];
      DenseInstance denseInstance0 = (DenseInstance)BallNode.calcCentroidPivot(74, (-1), intArray0, instances0);
      assertEquals(5, intArray0.length);
      assertNotNull(denseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0}, intArray0);
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, denseInstance0.numAttributes());
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(2, denseInstance0.numValues());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce(doubleArray0, (Instance) denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test073()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[4];
      doubleArray0[0] = (double) 1;
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      assertEquals(4, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {1.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(1, sparseInstance0.numValues());
      assertEquals(4, sparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce(doubleArray0, (Instance) sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test074()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce((Classifier) simpleLinearRegression0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test075()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      
      try { 
        evaluation0.evaluateModelOnce((double) 2, (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test076()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      
      int[] intArray0 = new int[2];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, intArray0, 0);
      assertEquals(2, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0}, intArray0);
      assertEquals(2, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(0, binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce((double) 2, (Instance) binarySparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test077()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      
      int[] intArray0 = new int[1];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(Double.NaN, intArray0, (-273));
      assertEquals(1, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0}, intArray0);
      assertEquals((-273), binarySparseInstance0.numAttributes());
      assertEquals(Double.NaN, binarySparseInstance0.weight(), 0.01);
      assertEquals(1, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce((double) 6, (Instance) binarySparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 6
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test078()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      DenseInstance denseInstance0 = new DenseInstance(5);
      assertNotNull(denseInstance0);
      assertEquals(1.0, denseInstance0.weight(), 0.01);
      assertEquals(5, denseInstance0.numAttributes());
      assertEquals(5, denseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      try { 
        evaluation0.evaluateModelOnce((-10.0), (Instance) denseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -10
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test079()  throws Throwable  {
      LWL lWL0 = new LWL();
      assertNotNull(lWL0);
      assertEquals("Determines weighting function. [0 = Linear, 1 = Epnechnikov,2 = Tricube, 3 = Inverse, 4 = Gaussian and 5 = Constant. (default 0 = Linear)].", lWL0.weightingKernelTipText());
      assertEquals(0, lWL0.getWeightingKernel());
      assertEquals((-1), lWL0.getKNN());
      assertEquals("The nearest neighbour search algorithm to use (Default: LinearNN).", lWL0.nearestNeighbourSearchAlgorithmTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", lWL0.debugTipText());
      assertEquals("The base classifier to be used.", lWL0.classifierTipText());
      assertFalse(lWL0.getDebug());
      assertEquals("How many neighbours are used to determine the width of the weighting function (<= 0 means all neighbours).", lWL0.KNNTipText());
      assertEquals(1, LWL.EPANECHNIKOV);
      assertEquals(2, LWL.TRICUBE);
      assertEquals(3, LWL.INVERSE);
      assertEquals(5, LWL.CONSTANT);
      assertEquals(0, LWL.LINEAR);
      assertEquals(4, LWL.GAUSS);
      
      String[] stringArray0 = new String[0];
      try { 
        Evaluation.evaluateModel((Classifier) lWL0, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: No training file and no object input file given.
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         // 
         // Options specific to weka.classifiers.lazy.LWL:
         // 
         // -A
         // \tThe nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).
         // 
         // -K <number of neighbours>
         // \tSet the number of neighbours used to set the kernel bandwidth.
         // \t(default all)
         // -U <number of weighting method>
         // \tSet the weighting kernel shape to use. 0=Linear, 1=Epanechnikov,
         // \t2=Tricube, 3=Inverse, 4=Gaussian.
         // \t(default 0 = Linear)
         // -D
         // \tIf set, classifier is run in debug mode and
         // \tmay output additional info to the console
         // -W
         // \tFull name of base classifier.
         // \t(default: weka.classifiers.trees.DecisionStump)
         // 
         // Options specific to classifier weka.classifiers.trees.DecisionStump:
         // 
         // -D
         // \tIf set, classifier is run in debug mode and
         // \tmay output additional info to the console
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test080()  throws Throwable  {
      String[] stringArray0 = new String[6];
      try { 
        Evaluation.evaluateModel((Classifier) null, stringArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test081()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      Object[] objectArray0 = new Object[2];
      try { 
        evaluation0.evaluateModel((Classifier) null, (Instances) null, objectArray0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test082()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances1 = testInstances0.generate();
      assertFalse(instances1.equals((Object)instances0));
      assertNotNull(instances1);
      assertNotSame(instances1, instances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, instances1.classIndex());
      assertEquals(20, instances1.numInstances());
      assertEquals(20, instances1.size());
      assertEquals("Testdata", instances1.relationName());
      assertEquals(2, instances1.numClasses());
      assertEquals(2, instances1.numAttributes());
      assertEquals(20.0, instances1.sumOfWeights(), 0.01);
      assertFalse(instances1.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      try { 
        evaluation0.evaluateModel((Classifier) null, instances1, (Object[]) testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test083()  throws Throwable  {
      try { 
        Evaluation.evaluateModel("R.C. Holte", (String[]) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name R.C. Holte.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test084()  throws Throwable  {
      String[] stringArray0 = new String[6];
      try { 
        Evaluation.evaluateModel((String) null, stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test085()  throws Throwable  {
      String[] stringArray0 = new String[8];
      try { 
        Evaluation.evaluateModel("", stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name .
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test086()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      
      String[] stringArray0 = new String[0];
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      SimpleLogistic simpleLogistic0 = new SimpleLogistic();
      assertNotNull(simpleLogistic0);
      assertEquals("Set fixed number of iterations for LogitBoost. If >= 0, this sets the number of LogitBoost iterations to perform. If < 0, the number is cross-validated or a stopping criterion on the training set is used (depending on the value of useCrossValidation).", simpleLogistic0.numBoostingIterationsTipText());
      assertEquals(500, simpleLogistic0.getMaxBoostingIterations());
      assertEquals("If heuristicStop > 0, the heuristic for greedy stopping while cross-validating the number of LogitBoost iterations is enabled. This means LogitBoost is stopped if no new error minimum has been reached in the last heuristicStop iterations. It is recommended to use this heuristic, it gives a large speed-up especially on small datasets. The default value is 50.", simpleLogistic0.heuristicStopTipText());
      assertEquals("Use error on the probabilties as error measure when determining the best number of LogitBoost iterations. If set, the number of LogitBoost iterations is chosen that minimizes the root mean squared error (either on the training set or in the cross-validation, depending on useCrossValidation).", simpleLogistic0.errorOnProbabilitiesTipText());
      assertFalse(simpleLogistic0.getDebug());
      assertEquals("Sets whether the number of LogitBoost iterations is to be cross-validated or the stopping criterion on the training set should be used. If not set (and no fixed number of iterations was given), the number of LogitBoost iterations is used that minimizes the error on the training set (misclassification error or error on probabilities depending on errorOnProbabilities).", simpleLogistic0.useCrossValidationTipText());
      assertEquals(0.0, simpleLogistic0.getWeightTrimBeta(), 0.01);
      assertEquals("Sets the maximum number of iterations for LogitBoost. Default value is 500, for very small/large datasets a lower/higher value might be preferable.", simpleLogistic0.maxBoostingIterationsTipText());
      assertFalse(simpleLogistic0.getErrorOnProbabilities());
      assertEquals("Set the beta value used for weight trimming in LogitBoost. Only instances carrying (1 - beta)% of the weight from previous iteration are used in the next iteration. Set to 0 for no weight trimming. The default value is 0.", simpleLogistic0.weightTrimBetaTipText());
      assertTrue(simpleLogistic0.getUseCrossValidation());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLogistic0.debugTipText());
      assertEquals(0, simpleLogistic0.getNumBoostingIterations());
      assertEquals("The AIC is used to determine when to stop LogitBoost iterations (instead of cross-validation or training error).", simpleLogistic0.useAICTipText());
      assertFalse(simpleLogistic0.getUseAIC());
      assertEquals(50, simpleLogistic0.getHeuristicStop());
      
      try { 
        evaluation0.crossValidateModel((Classifier) simpleLogistic0, instances0, (-1471), (Random) mockRandom0, (Object[]) stringArray0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Number of folds must be greater than 1
         //
         verifyException("weka.core.Instances", e);
      }
  }

  @Test(timeout = 4000)
  public void test087()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      MockRandom mockRandom0 = new MockRandom(266L);
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel((Classifier) costSensitiveClassifier0, instances0, (-2), (Random) mockRandom0, (Object[]) testInstances0.DEFAULT_WORDS);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Number of folds must be greater than 1
         //
         verifyException("weka.core.Instances", e);
      }
  }

  @Test(timeout = 4000)
  public void test088()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      
      MultiClassClassifierUpdateable multiClassClassifierUpdateable0 = new MultiClassClassifierUpdateable();
      assertNotNull(multiClassClassifierUpdateable0);
      assertFalse(multiClassClassifierUpdateable0.getDebug());
      assertEquals("A metaclassifier for handling multi-class datasets with 2-class classifiers. This classifier is also capable of applying error correcting output codes for increased accuracy. The base classifier must be an updateable classifier", multiClassClassifierUpdateable0.globalInfo());
      assertEquals("Use pairwise coupling (only has an effect for 1-against-1).", multiClassClassifierUpdateable0.usePairwiseCouplingTipText());
      assertFalse(multiClassClassifierUpdateable0.getUsePairwiseCoupling());
      assertEquals("Sets the width multiplier when using random codes. The number of codes generated will be thus number multiplied by the number of classes.", multiClassClassifierUpdateable0.randomWidthFactorTipText());
      assertEquals("The base classifier to be used.", multiClassClassifierUpdateable0.classifierTipText());
      assertEquals(2.0, multiClassClassifierUpdateable0.getRandomWidthFactor(), 0.01);
      assertEquals("The random number seed to be used.", multiClassClassifierUpdateable0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", multiClassClassifierUpdateable0.debugTipText());
      assertEquals("Sets the method to use for transforming the multi-class problem into several 2-class ones.", multiClassClassifierUpdateable0.methodTipText());
      assertEquals(1, multiClassClassifierUpdateable0.getSeed());
      assertEquals(2, MultiClassClassifier.METHOD_ERROR_EXHAUSTIVE);
      assertEquals(1, MultiClassClassifier.METHOD_ERROR_RANDOM);
      assertEquals(0, MultiClassClassifier.METHOD_1_AGAINST_ALL);
      assertEquals(3, MultiClassClassifier.METHOD_1_AGAINST_1);
      
      try { 
        evaluation0.crossValidateModel((Classifier) null, instances0, 970, (Random) null, (Object[]) multiClassClassifierUpdateable0.TAGS_METHOD);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // weka.core.Tag cannot be cast to weka.classifiers.evaluation.output.prediction.AbstractOutput
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test089()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      String[] stringArray0 = new String[0];
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel("import weka.core.Capabilities.Capability;\n", instances0, 4, stringArray0, (Random) mockRandom0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: import weka.core.Capabilities.Capability;
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test090()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(5, testInstances0.getNumAttributes());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.numInstances());
      assertEquals(4, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      try { 
        evaluation0.crossValidateModel(".bsi", instances0, 0, testInstances0.DEFAULT_WORDS, (Random) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: .bsi
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test091()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      try { 
        evaluation0.crossValidateModel(".bsi", (Instances) null, (-2600), (String[]) null, (Random) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: .bsi
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test092()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel((String) null, instances0, 10000, testInstances0.DEFAULT_WORDS, (Random) mockRandom0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: null
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test093()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      
      String[] stringArray0 = new String[8];
      try { 
        evaluation0.crossValidateModel("", instances0, 1497, stringArray0, (Random) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class called: 
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test094()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.areaUnderROC((-1));
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), testInstances0.getClassIndex());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test095()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.areaUnderPRC((-2));
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test096()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      evaluation0.addNumericTrainClass(1998.59162660989, 0.0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test097()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      
      evaluation0.addNumericTrainClass(0.0, (-1432));
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
  }

  @Test(timeout = 4000)
  public void test098()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      evaluation0.addNumericTrainClass(2, 2);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumString());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(3, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test099()  throws Throwable  {
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      assertNotNull(filteredClassifier0);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      
      Capabilities capabilities0 = new Capabilities(filteredClassifier0);
      assertNotNull(capabilities0);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      evaluation0.addNumericTrainClass((-4405.701632700381), 74);
      assertEquals("If set to true, classifier may output additional info to the console.", filteredClassifier0.debugTipText());
      assertEquals("The filter to be used.", filteredClassifier0.filterTipText());
      assertEquals("Class for running an arbitrary classifier on data that has been passed through an arbitrary filter. Like the classifier, the structure of the filter is based exclusively on the training data and test instances will be processed by the filter without changing their structure.", filteredClassifier0.globalInfo());
      assertFalse(filteredClassifier0.getDebug());
      assertEquals("The base classifier to be used.", filteredClassifier0.classifierTipText());
      assertEquals(1, filteredClassifier0.graphType());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test100()  throws Throwable  {
      try { 
        Evaluation.wekaStaticWrapper((Sourcable) null, "1dL)\"");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test101()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(3, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(2, instances0.classIndex());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      // Undeclared exception!
      try { 
        evaluation0.weightedRecall();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test102()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      evaluation0.m_NumClasses = 11;
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.weightedFalseNegativeRate();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test103()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      try { 
        evaluation0.updateStatsForPredictor(1289.0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test104()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      
      SparseInstance sparseInstance0 = new SparseInstance(0);
      assertNotNull(sparseInstance0);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((Instance) sparseInstance0);
      assertNotNull(binarySparseInstance0);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(0, sparseInstance0.numAttributes());
      assertEquals(1.0, sparseInstance0.weight(), 0.01);
      assertEquals(0, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForIntervalEstimator(gaussianProcesses0, binarySparseInstance0, 6);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test105()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updateStatsForClassifier(doubleArray0, binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test106()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      
      double[] doubleArray0 = new double[1];
      int[] intArray0 = new int[7];
      SparseInstance sparseInstance0 = new SparseInstance((-3371.3132378726), doubleArray0, intArray0, 1409);
      assertEquals(1, doubleArray0.length);
      assertEquals(7, intArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0}, doubleArray0, 0.01);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals((-3371.3132378726), sparseInstance0.weight(), 0.01);
      assertEquals(1409, sparseInstance0.numAttributes());
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.updatePriors(sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test107()  throws Throwable  {
      KernelEstimator kernelEstimator0 = new KernelEstimator((-1.0));
      assertNotNull(kernelEstimator0);
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(kernelEstimator0.getDebug());
      
      Capabilities capabilities0 = new Capabilities(kernelEstimator0);
      assertNotNull(capabilities0);
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(kernelEstimator0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(kernelEstimator0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(kernelEstimator0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1.6666666666666665E-7, kernelEstimator0.getStdDev(), 0.01);
      assertEquals("If set to true, estimator may output additional info to the console.", kernelEstimator0.debugTipText());
      assertEquals(1.0E-6, kernelEstimator0.getPrecision(), 0.01);
      assertEquals(0, kernelEstimator0.getNumKernels());
      assertFalse(kernelEstimator0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(1, testInstances0.getClassType());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      try { 
        evaluation0.updatePriors((Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test108()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.updateMargins((double[]) null, (-1826), (-455.485507071));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test109()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double[] doubleArray0 = new double[0];
      // Undeclared exception!
      try { 
        evaluation0.updateMargins(doubleArray0, (-795), (-795));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -795
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test110()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      try { 
        evaluation0.toClassDetailsString();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No per class statistics possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test111()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      
      try { 
        evaluation0.setPriors((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test112()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      // Undeclared exception!
      try { 
        evaluation0.recall((-1));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // -1
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test113()  throws Throwable  {
      PrecomputedKernelMatrixKernel precomputedKernelMatrixKernel0 = new PrecomputedKernelMatrixKernel();
      assertNotNull(precomputedKernelMatrixKernel0);
      assertEquals("Turns time-consuming checks off - use with caution.", precomputedKernelMatrixKernel0.checksTurnedOffTipText());
      assertEquals("The file holding the kernel matrix.", precomputedKernelMatrixKernel0.kernelMatrixFileTipText());
      assertFalse(precomputedKernelMatrixKernel0.getDebug());
      assertEquals(0, precomputedKernelMatrixKernel0.numEvals());
      assertEquals(0, precomputedKernelMatrixKernel0.numCacheHits());
      assertFalse(precomputedKernelMatrixKernel0.getChecksTurnedOff());
      assertEquals("This kernel is based on a static kernel matrix that is read from a file. Instances must have a single nominal attribute (excluding the class). This attribute must be the first attribute in the file and its values are used to reference rows/columns in the kernel matrix. The second attribute must be the class attribute.", precomputedKernelMatrixKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", precomputedKernelMatrixKernel0.debugTipText());
      
      Capabilities capabilities0 = new Capabilities(precomputedKernelMatrixKernel0);
      assertNotNull(capabilities0);
      assertEquals("Turns time-consuming checks off - use with caution.", precomputedKernelMatrixKernel0.checksTurnedOffTipText());
      assertEquals("The file holding the kernel matrix.", precomputedKernelMatrixKernel0.kernelMatrixFileTipText());
      assertFalse(precomputedKernelMatrixKernel0.getDebug());
      assertEquals(0, precomputedKernelMatrixKernel0.numEvals());
      assertEquals(0, precomputedKernelMatrixKernel0.numCacheHits());
      assertFalse(precomputedKernelMatrixKernel0.getChecksTurnedOff());
      assertEquals("This kernel is based on a static kernel matrix that is read from a file. Instances must have a single nominal attribute (excluding the class). This attribute must be the first attribute in the file and its values are used to reference rows/columns in the kernel matrix. The second attribute must be the class attribute.", precomputedKernelMatrixKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", precomputedKernelMatrixKernel0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("Turns time-consuming checks off - use with caution.", precomputedKernelMatrixKernel0.checksTurnedOffTipText());
      assertEquals("The file holding the kernel matrix.", precomputedKernelMatrixKernel0.kernelMatrixFileTipText());
      assertFalse(precomputedKernelMatrixKernel0.getDebug());
      assertEquals(0, precomputedKernelMatrixKernel0.numEvals());
      assertEquals(0, precomputedKernelMatrixKernel0.numCacheHits());
      assertFalse(precomputedKernelMatrixKernel0.getChecksTurnedOff());
      assertEquals("This kernel is based on a static kernel matrix that is read from a file. Instances must have a single nominal attribute (excluding the class). This attribute must be the first attribute in the file and its values are used to reference rows/columns in the kernel matrix. The second attribute must be the class attribute.", precomputedKernelMatrixKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", precomputedKernelMatrixKernel0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("Turns time-consuming checks off - use with caution.", precomputedKernelMatrixKernel0.checksTurnedOffTipText());
      assertEquals("The file holding the kernel matrix.", precomputedKernelMatrixKernel0.kernelMatrixFileTipText());
      assertFalse(precomputedKernelMatrixKernel0.getDebug());
      assertEquals(0, precomputedKernelMatrixKernel0.numEvals());
      assertEquals(0, precomputedKernelMatrixKernel0.numCacheHits());
      assertFalse(precomputedKernelMatrixKernel0.getChecksTurnedOff());
      assertEquals("This kernel is based on a static kernel matrix that is read from a file. Instances must have a single nominal attribute (excluding the class). This attribute must be the first attribute in the file and its values are used to reference rows/columns in the kernel matrix. The second attribute must be the class attribute.", precomputedKernelMatrixKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", precomputedKernelMatrixKernel0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Turns time-consuming checks off - use with caution.", precomputedKernelMatrixKernel0.checksTurnedOffTipText());
      assertEquals("The file holding the kernel matrix.", precomputedKernelMatrixKernel0.kernelMatrixFileTipText());
      assertFalse(precomputedKernelMatrixKernel0.getDebug());
      assertEquals(0, precomputedKernelMatrixKernel0.numEvals());
      assertEquals(0, precomputedKernelMatrixKernel0.numCacheHits());
      assertFalse(precomputedKernelMatrixKernel0.getChecksTurnedOff());
      assertEquals("This kernel is based on a static kernel matrix that is read from a file. Instances must have a single nominal attribute (excluding the class). This attribute must be the first attribute in the file and its values are used to reference rows/columns in the kernel matrix. The second attribute must be the class attribute.", precomputedKernelMatrixKernel0.globalInfo());
      assertEquals("Turns on the output of debugging information.", precomputedKernelMatrixKernel0.debugTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      // Undeclared exception!
      try { 
        evaluation0.precision(4);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 4
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test114()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      
      char[] charArray0 = new char[2];
      // Undeclared exception!
      try { 
        evaluation0.num2ShortID(1111, charArray0, (-197112209));
        fail("Expecting exception: NegativeArraySizeException");
      
      } catch(NegativeArraySizeException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test115()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      
      char[] charArray0 = new char[0];
      // Undeclared exception!
      try { 
        evaluation0.num2ShortID(1274, charArray0, 103);
        fail("Expecting exception: ArithmeticException");
      
      } catch(ArithmeticException e) {
         //
         // / by zero
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test116()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = new EvoSuiteFile("O Qg@IH')M-k/a2qH7");
      boolean boolean0 = FileSystemHandling.appendStringToFile(evoSuiteFile0, "  public static Object[] filter(Object[] i) {\n");
      assertTrue(boolean0);
      
      try { 
        Evaluation.handleCostOption("O Qg@IH')M-k/a2qH7", 0);
        fail("Expecting exception: NumberFormatException");
      
      } catch(NumberFormatException e) {
         //
         // For input string: \"public\"
         //
         verifyException("java.lang.NumberFormatException", e);
      }
  }

  @Test(timeout = 4000)
  public void test117()  throws Throwable  {
      try { 
        Evaluation.getGlobalInfo((Classifier) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test118()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      double[] doubleArray0 = new double[6];
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, (Instance) null, false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test119()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(0, instances0.numClasses());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(46);
      assertNotNull(binarySparseInstance0);
      assertEquals(46, binarySparseInstance0.numValues());
      assertEquals(46, binarySparseInstance0.numAttributes());
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      double[] doubleArray0 = new double[0];
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, binarySparseInstance0, false);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test120()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      double[] doubleArray0 = new double[3];
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test121()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(3, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      assertEquals(3, doubleArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(1.0, binarySparseInstance0.weight(), 0.01);
      assertEquals(0, binarySparseInstance0.numValues());
      assertEquals(3, binarySparseInstance0.numAttributes());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) costSensitiveClassifier0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test122()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double[] doubleArray0 = new double[4];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      assertEquals(4, doubleArray0.length);
      assertNotNull(sparseInstance0);
      assertArrayEquals(new double[] {0.0, 0.0, 0.0, 0.0}, doubleArray0, 0.01);
      assertEquals(0, sparseInstance0.numValues());
      assertEquals(4, sparseInstance0.numAttributes());
      assertEquals(0.0, sparseInstance0.weight(), 0.01);
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce(doubleArray0, (Instance) sparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test123()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      
      double[] doubleArray0 = new double[0];
      try { 
        evaluation0.evaluateModelOnce(doubleArray0, (Instance) null);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test124()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = sGDText0.getCapabilities();
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(4, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(5, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(1, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumString());
      assertEquals(4, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(5, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      int[] intArray0 = new int[7];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1242.1), intArray0, 1);
      assertEquals(7, intArray0.length);
      assertNotNull(binarySparseInstance0);
      assertArrayEquals(new int[] {0, 0, 0, 0, 0, 0, 0}, intArray0);
      assertEquals(1, binarySparseInstance0.numAttributes());
      assertEquals((-1242.1), binarySparseInstance0.weight(), 0.01);
      assertEquals(7, binarySparseInstance0.numValues());
      assertEquals(6, AbstractInstance.s_numericAfterDecimalPoint);
      
      try { 
        evaluation0.evaluateModelOnce(0.0, (Instance) binarySparseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test125()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      
      PART pART0 = new PART();
      assertNotNull(pART0);
      assertFalse(pART0.getReducedErrorPruning());
      assertEquals("The confidence factor used for pruning (smaller values incur more pruning).", pART0.confidenceFactorTipText());
      assertFalse(pART0.getUnpruned());
      assertFalse(pART0.getDebug());
      assertEquals("The minimum number of instances per rule.", pART0.minNumObjTipText());
      assertFalse(pART0.getBinarySplits());
      assertEquals("Determines the amount of data used for reduced-error pruning.  One fold is used for pruning, the rest for growing the rules.", pART0.numFoldsTipText());
      assertEquals("Whether pruning is performed.", pART0.unprunedTipText());
      assertEquals(1, pART0.getSeed());
      assertEquals(0.25F, pART0.getConfidenceFactor(), 0.01F);
      assertEquals("Whether MDL correction is used when finding splits on numeric attributes.", pART0.useMDLcorrectionTipText());
      assertTrue(pART0.getUseMDLcorrection());
      assertEquals("If set to true, classifier may output additional info to the console.", pART0.debugTipText());
      assertEquals("Whether to use binary splits on nominal attributes when building the partial trees.", pART0.binarySplitsTipText());
      assertEquals(2, pART0.getMinNumObj());
      assertEquals(3, pART0.getNumFolds());
      assertEquals("Whether reduced-error pruning is used instead of C.4.5 pruning.", pART0.reducedErrorPruningTipText());
      assertEquals("The seed used for randomizing the data when reduced-error pruning is used.", pART0.seedTipText());
      
      try { 
        evaluation0.evaluateModel((Classifier) pART0, instances0, (Object[]) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test126()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      
      Instances instances0 = textDirectoryLoader0.getStructure();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      MockRandom mockRandom0 = new MockRandom();
      assertNotNull(mockRandom0);
      
      try { 
        evaluation0.crossValidateModel((Classifier) costSensitiveClassifier0, instances0, 0, (Random) mockRandom0, (Object[]) costSensitiveClassifier0.TAGS_MATRIX_SOURCE);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Number of folds must be greater than 1
         //
         verifyException("weka.core.Instances", e);
      }
  }

  @Test(timeout = 4000)
  public void test127()  throws Throwable  {
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      assertNotNull(costSensitiveClassifier0);
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      assertNotNull(costMatrix0);
      assertEquals(1, costSensitiveClassifier0.getSeed());
      assertFalse(costSensitiveClassifier0.getDebug());
      assertEquals("If set to true, classifier may output additional info to the console.", costSensitiveClassifier0.debugTipText());
      assertEquals("The random number seed to be used.", costSensitiveClassifier0.seedTipText());
      assertEquals("A metaclassifier that makes its base classifier cost-sensitive. Two methods can be used to introduce cost-sensitivity: reweighting training instances according to the total cost assigned to each class; or predicting the class with minimum expected misclassification cost (rather than the most likely class). Performance can often be improved by using a Bagged classifier to improve the probability estimates of the base classifier.", costSensitiveClassifier0.globalInfo());
      assertEquals("Sets the directory where cost files are loaded from. This option is used when the costMatrixSource is set to \"On Demand\".", costSensitiveClassifier0.onDemandDirectoryTipText());
      assertEquals("The base classifier to be used.", costSensitiveClassifier0.classifierTipText());
      assertEquals(0, costSensitiveClassifier0.graphType());
      assertEquals("Sets the cost matrix explicitly. This matrix is used if the costMatrixSource property is set to \"Supplied\".", costSensitiveClassifier0.costMatrixTipText());
      assertFalse(costSensitiveClassifier0.getMinimizeExpectedCost());
      assertEquals("Sets whether the minimum expected cost criteria will be used. If this is false, the training data will be reweighted according to the costs assigned to each class. If true, the minimum expected cost criteria will be used.", costSensitiveClassifier0.minimizeExpectedCostTipText());
      assertEquals(1, costMatrix0.numColumns());
      assertEquals(1, costMatrix0.size());
      assertEquals(1, costMatrix0.numRows());
      assertEquals(2, CostSensitiveClassifier.MATRIX_SUPPLIED);
      assertEquals(1, CostSensitiveClassifier.MATRIX_ON_DEMAND);
      
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation((Instances) null, costMatrix0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test128()  throws Throwable  {
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation((Instances) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test129()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      evaluation0.setPriors(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test130()  throws Throwable  {
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      assertNotNull(gaussianProcesses0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      
      Capabilities capabilities0 = gaussianProcesses0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      evaluation0.setPriors(instances0);
      assertEquals(1.0, gaussianProcesses0.getNoise(), 0.01);
      assertEquals("Determines how/if the data will be transformed.", gaussianProcesses0.filterTypeTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", gaussianProcesses0.debugTipText());
      assertFalse(gaussianProcesses0.getDebug());
      assertEquals("The level of Gaussian Noise (added to the diagonal of the Covariance Matrix), after the target has been normalized/standardized/left unchanged).", gaussianProcesses0.noiseTipText());
      assertEquals(" Implements Gaussian processes for regression without hyperparameter-tuning. To make choosing an appropriate noise level easier, this implementation applies normalization/standardization to the target attribute as well as the other attributes (if  normalization/standardizaton is turned on). Missing values are replaced by the global mean/mode. Nominal attributes are converted to binary ones. Note that kernel caching is turned off if the kernel used implements CachedKernel.", gaussianProcesses0.globalInfo());
      assertEquals("The kernel to use.", gaussianProcesses0.kernelTipText());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertTrue(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getNumNumeric());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(2, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(3, instances0.numAttributes());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numClasses());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1, GaussianProcesses.FILTER_STANDARDIZE);
      assertEquals(0, GaussianProcesses.FILTER_NORMALIZE);
      assertEquals(2, GaussianProcesses.FILTER_NONE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test131()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.weightedFMeasure();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test132()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      double double0 = evaluation0.fMeasure(11);
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numClasses());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
  }

  @Test(timeout = 4000)
  public void test133()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.weightedPrecision();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test134()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.precision(1);
      assertEquals(0.0, double0, 0.01);
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test135()  throws Throwable  {
      JRip jRip0 = new JRip();
      assertNotNull(jRip0);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      
      Capabilities capabilities0 = jRip0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals(3, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals(3, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate(" I8itRrt{JDp+D^8wj");
      assertNotNull(instances0);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals(3, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals(3, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.weightedMatthewsCorrelation();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The seed used for randomizing the data.", jRip0.seedTipText());
      assertFalse(jRip0.getDebug());
      assertEquals("The number of optimization runs.", jRip0.optimizationsTipText());
      assertTrue(jRip0.getUsePruning());
      assertEquals(1L, jRip0.getSeed());
      assertTrue(jRip0.getCheckErrorRate());
      assertEquals("Whether pruning is performed.", jRip0.usePruningTipText());
      assertEquals("The minimum total weight of the instances in a rule.", jRip0.minNoTipText());
      assertEquals(2.0, jRip0.getMinNo(), 0.01);
      assertEquals(3, jRip0.getFolds());
      assertEquals("Whether debug information is output to the console.", jRip0.debugTipText());
      assertEquals(2, jRip0.getOptimizations());
      assertEquals("Whether check for error rate >= 1/2 is included in stopping criterion.", jRip0.checkErrorRateTipText());
      assertEquals("Determines the amount of data used for pruning. One fold is used for pruning, the rest for growing the rules.", jRip0.foldsTipText());
      assertEquals(3, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(4, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test136()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      assertNotNull(simpleLinearRegression0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.numAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("If set to true, classifier may output additional info to the console.", simpleLinearRegression0.debugTipText());
      assertEquals(0.0, simpleLinearRegression0.getIntercept(), 0.01);
      assertEquals("Learns a simple linear regression model. Picks the attribute that results in the lowest squared error. Missing values are not allowed. Can only deal with numeric attributes.", simpleLinearRegression0.globalInfo());
      assertEquals(0, simpleLinearRegression0.getAttributeIndex());
      assertFalse(simpleLinearRegression0.getDebug());
      assertFalse(simpleLinearRegression0.foundUsefulAttribute());
      assertEquals(0.0, simpleLinearRegression0.getSlope(), 0.01);
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(3, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.numAttributes());
      assertEquals(2, instances0.classIndex());
      assertEquals(1, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      // Undeclared exception!
      try { 
        evaluation0.weightedMatthewsCorrelation();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test137()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      
      double double0 = evaluation0.matthewsCorrelationCoefficient(802);
      assertEquals(0.0, double0, 0.01);
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(0, instances0.numInstances());
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
  }

  @Test(timeout = 4000)
  public void test138()  throws Throwable  {
      RandomTree randomTree0 = new RandomTree();
      assertNotNull(randomTree0);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      
      Capabilities capabilities0 = new Capabilities(randomTree0);
      assertNotNull(capabilities0);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.numFalseNegatives(1);
      assertEquals(0.0, double0, 0.01);
      assertFalse(randomTree0.getAllowUnclassifiedInstances());
      assertEquals(1, randomTree0.graphType());
      assertEquals("Determines the amount of data used for backfitting. One fold is used for backfitting, the rest for growing the tree. (Default: 0, no backfitting)", randomTree0.numFoldsTipText());
      assertEquals(0, randomTree0.getKValue());
      assertEquals(0, randomTree0.getMaxDepth());
      assertEquals(1, randomTree0.numElements());
      assertEquals("If set to true, classifier may output additional info to the console.", randomTree0.debugTipText());
      assertEquals(0, randomTree0.getNumFolds());
      assertEquals(1.0, randomTree0.getMinNum(), 0.01);
      assertEquals("The random number seed used for selecting attributes.", randomTree0.seedTipText());
      assertEquals("Whether to allow unclassified instances.", randomTree0.allowUnclassifiedInstancesTipText());
      assertEquals("The maximum depth of the tree, 0 for unlimited.", randomTree0.maxDepthTipText());
      assertEquals(1, randomTree0.getSeed());
      assertEquals(1, randomTree0.numNodes());
      assertFalse(randomTree0.getDebug());
      assertEquals("Sets the number of randomly chosen attributes. If 0, log_2(number_of_attributes) + 1 is used.", randomTree0.KValueTipText());
      assertEquals("The minimum total weight of the instances in a leaf.", randomTree0.minNumTipText());
      assertEquals("Class for constructing a tree that considers K randomly  chosen attributes at each node. Performs no pruning. Also has an option to allow estimation of class probabilities based on a hold-out set (backfitting).", randomTree0.globalInfo());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test139()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.numFalseNegatives((-1635));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test140()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.weightedFalsePositiveRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumString());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.size());
      assertEquals(20, instances0.numInstances());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test141()  throws Throwable  {
      OneRAttributeEval oneRAttributeEval0 = new OneRAttributeEval();
      assertNotNull(oneRAttributeEval0);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      
      Capabilities capabilities0 = oneRAttributeEval0.getCapabilities();
      assertNotNull(capabilities0);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      assertNotNull(evaluation0);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.falsePositiveRate(3);
      assertEquals(0.0, double0, 0.01);
      assertEquals(1, oneRAttributeEval0.getSeed());
      assertFalse(oneRAttributeEval0.getEvalUsingTrainingData());
      assertEquals("Use the training data to evaluate attributes rather than cross validation.", oneRAttributeEval0.evalUsingTrainingDataTipText());
      assertEquals(6, oneRAttributeEval0.getMinimumBucketSize());
      assertEquals(10, oneRAttributeEval0.getFolds());
      assertEquals("OneRAttributeEval :\n\nEvaluates the worth of an attribute by using the OneR classifier.\n", oneRAttributeEval0.globalInfo());
      assertEquals("Set the seed for use in cross validation.", oneRAttributeEval0.seedTipText());
      assertEquals("The minimum number of objects in a bucket (passed to OneR).", oneRAttributeEval0.minimumBucketSizeTipText());
      assertEquals("Set the number of folds for cross validation.", oneRAttributeEval0.foldsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, capabilities0.getMinimumNumberInstances());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertEquals(1, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumRelationalDate());
      assertEquals(1, testInstances0.getNumNumeric());
      assertEquals(4, testInstances0.getNumAttributes());
      assertEquals(4, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(4, instances0.numAttributes());
      assertEquals(20, instances0.numInstances());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(4, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(3, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test142()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      
      double double0 = evaluation0.falsePositiveRate((-5454));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals(2, instances0.numAttributes());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0, instances0.numInstances());
      assertEquals(1, instances0.classIndex());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
  }

  @Test(timeout = 4000)
  public void test143()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      
      evaluation0.m_NumClasses = 6;
      assertFalse(textDirectoryLoader0.getDebug());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertEquals(0, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numClasses());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.size());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      
      // Undeclared exception!
      try { 
        evaluation0.falsePositiveRate(3163);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test144()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.numFalsePositives(0);
      assertEquals(0.0, double0, 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test145()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      assertNotNull(instances0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.numFalsePositives(9);
      assertEquals(0.0, double0, 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test146()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.trueNegativeRate(1);
      assertEquals(0.0, double0, 0.01);
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(testInstances0.getNoClass());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(20, instances0.numInstances());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(2, instances0.numClasses());
      assertEquals(1, instances0.numAttributes());
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test147()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.numTrueNegatives(0);
      assertEquals(0.0, double0, 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertFalse(sGDText0.getDebug());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals(1, sGDText0.getSeed());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumClasses());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(20, instances0.size());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numClasses());
      assertEquals(0, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test148()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate("%YBe.O#ACZ2k");
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.numTrueNegatives(907);
      assertEquals(0.0, double0, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, testInstances0.getNumString());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(2, instances0.numAttributes());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test149()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
      
      double double0 = evaluation0.weightedTruePositiveRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertFalse(sGDText0.getDebug());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getUseStopList());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, instances0.size());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals(20, instances0.numInstances());
      assertEquals(0, instances0.classIndex());
      assertEquals(1, instances0.numAttributes());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0, SGDText.HINGE);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      assertEquals((-2), TestInstances.NO_CLASS);
  }

  @Test(timeout = 4000)
  public void test150()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      assertNotNull(testInstances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      double double0 = evaluation0.truePositiveRate(1);
      assertEquals(0.0, double0, 0.01);
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(1, testInstances0.getNumRelationalNominal());
      assertFalse(testInstances0.getMultiInstance());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertEquals(1, testInstances0.getNumNominal());
      assertEquals(2, testInstances0.getNumAttributes());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(2, instances0.numClasses());
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(2, instances0.numAttributes());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(1, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
  }

  @Test(timeout = 4000)
  public void test151()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      assertNotNull(textDirectoryLoader0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      
      Instances instances0 = textDirectoryLoader0.getDataSet();
      assertNotNull(instances0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      
      double double0 = evaluation0.truePositiveRate((-1432));
      assertEquals(0.0, double0, 0.01);
      assertEquals("Whether to print additional debug information to the console.", textDirectoryLoader0.debugTipText());
      assertEquals("", textDirectoryLoader0.getCharSet());
      assertEquals("Directories", textDirectoryLoader0.getFileDescription());
      assertFalse(textDirectoryLoader0.getDebug());
      assertEquals("Loads all text files in a directory and uses the subdirectory names as class labels. The content of the text files will be stored in a String attribute, the filename can be stored as well.", textDirectoryLoader0.globalInfo());
      assertFalse(textDirectoryLoader0.getOutputFilename());
      assertEquals("The character set to use when reading text files (eg UTF-8) - leave blank to use the default character set.", textDirectoryLoader0.charSetTipText());
      assertEquals("Whether to store the filename in an additional attribute.", textDirectoryLoader0.outputFilenameTipText());
      assertEquals(2, instances0.numAttributes());
      assertEquals(1, instances0.classIndex());
      assertEquals(0, instances0.numClasses());
      assertEquals(0.0, instances0.sumOfWeights(), 0.01);
      assertTrue(instances0.checkForStringAttributes());
      assertEquals(0, instances0.numInstances());
      assertEquals(0, instances0.size());
      assertEquals("_home_apaniche_performance_Dataset_gordon_scripts_projects_9_weka", instances0.relationName());
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
  }

  @Test(timeout = 4000)
  public void test152()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      assertNotNull(sGDText0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      Capabilities capabilities0 = new Capabilities(sGDText0);
      assertNotNull(capabilities0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      assertNotNull(testInstances0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Instances instances0 = testInstances0.generate();
      assertNotNull(instances0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      Evaluation evaluation0 = new Evaluation(instances0);
      assertNotNull(evaluation0);
      assertEquals(1.0E-4, sGDText0.getLambda(), 0.01);
      assertEquals("How often (number of instances) to prune the dictionary of low frequency terms. 0 means don't prune. Setting a positive integer n means prune after every n instances", sGDText0.periodicPruningTipText());
      assertEquals("Fit a logistic regression to the output of SVM for producing probability estimates", sGDText0.outputProbsForSVMTipText());
      assertEquals("Use word frequencies rather than binary bag of words representation", sGDText0.useWordFrequenciesTipText());
      assertEquals("Ignore any words that don't occur at least min frequency times in the training data. If periodic pruning is turned on, then the dictionary is pruned according to this value", sGDText0.minWordFrequencyTipText());
      assertFalse(sGDText0.getDebug());
      assertFalse(sGDText0.getOutputProbsForSVM());
      assertEquals("If true then document length is normalized according to the settings for norm and lnorm", sGDText0.normalizeDocLengthTipText());
      assertEquals("The LNorm to use for document length normalization.", sGDText0.LNormTipText());
      assertEquals(1, sGDText0.getSeed());
      assertEquals(1.0, sGDText0.getNorm(), 0.01);
      assertEquals("The number of epochs to perform (batch learning). The total number of iterations is epochs * num instances.", sGDText0.epochsTipText());
      assertEquals("Whether to convert all tokens to lowercase", sGDText0.lowercaseTokensTipText());
      assertEquals("The loss function to use. Hinge loss (SVM), log loss (logistic regression) or squared loss (regression).", sGDText0.lossFunctionTipText());
      assertEquals("Implements stochastic gradient descent for learning a linear binary class SVM or binary class logistic regression on text data. Operates directly (and only) on String attributes. Other types of input attributes are accepted but ignored during training and classification.", sGDText0.globalInfo());
      assertEquals("The learning rate.", sGDText0.learningRateTipText());
      assertEquals(0.01, sGDText0.getLearningRate(), 0.01);
      assertEquals("The random number seed to be used.", sGDText0.seedTipText());
      assertEquals("If true, ignores all words that are on the stoplist.", sGDText0.useStopListTipText());
      assertFalse(sGDText0.getNormalizeDocLength());
      assertFalse(sGDText0.getUseWordFrequencies());
      assertEquals("The regularization constant. (default = 0.0001)", sGDText0.lambdaTipText());
      assertEquals("The norm of the instances after normalization.", sGDText0.normTipText());
      assertEquals("The file containing the stopwords (if this is a directory then the default ones are used).", sGDText0.stopwordsTipText());
      assertEquals(2.0, sGDText0.getLNorm(), 0.01);
      assertEquals(500, sGDText0.getEpochs());
      assertEquals("The stemming algorithm to use on the words.", sGDText0.stemmerTipText());
      assertEquals("The tokenizing algorithm to use on the strings.", sGDText0.tokenizerTipText());
      assertEquals("If set to true, classifier may output additional info to the console.", sGDText0.debugTipText());
      assertFalse(sGDText0.getUseStopList());
      assertFalse(sGDText0.getLowercaseTokens());
      assertEquals(3.0, sGDText0.getMinWordFrequency(), 0.01);
      assertEquals(0, sGDText0.getPeriodicPruning());
      assertFalse(capabilities0.hasDependencies());
      assertEquals(0, capabilities0.getMinimumNumberInstances());
      assertEquals(0, testInstances0.getNumString());
      assertEquals(0, testInstances0.getNumRelational());
      assertEquals(2, testInstances0.getNumClasses());
      assertEquals(1, testInstances0.getNumAttributes());
      assertEquals(0, testInstances0.getNumRelationalNominal());
      assertEquals(0, testInstances0.getNumRelationalNumeric());
      assertEquals((-1), testInstances0.getClassIndex());
      assertEquals(2, testInstances0.getNumRelationalNominalValues());
      assertEquals(0, testInstances0.getNumNumeric());
      assertEquals(2, testInstances0.getNumNominalValues());
      assertFalse(testInstances0.getMultiInstance());
      assertFalse(testInstances0.getNoClass());
      assertEquals(20, testInstances0.getNumInstances());
      assertEquals(0, testInstances0.getNumRelationalString());
      assertEquals(0, testInstances0.getNumNominal());
      assertEquals(1, testInstances0.getClassType());
      assertEquals(1, testInstances0.getSeed());
      assertEquals(" ", testInstances0.getWordSeparators());
      assertEquals("Testdata", testInstances0.getRelation());
      assertEquals(0, testInstances0.getNumRelationalDate());
      assertEquals(10, testInstances0.getNumInstancesRelational());
      assertEquals(0, testInstances0.getNumDate());
      assertEquals(1, instances0.numAttributes());
      assertEquals(2, instances0.numClasses());
      assertEquals("Testdata", instances0.relationName());
      assertEquals(0, instances0.classIndex());
      assertEquals(20, instances0.numInstances());
      assertEquals(20, instances0.size());
      assertEquals(20.0, instances0.sumOfWeights(), 0.01);
      assertFalse(instances0.checkForStringAttributes());
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootRelativeSquaredError(), 0.01);
      assertEquals(Double.NaN, evaluation0.coverageOfTestCasesByPredictedRegions(), 0.01);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTrueNegativeRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanPriorEntropy(), 0.01);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.correct(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanEntropyGain(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctUnclassified(), 0.01);
      assertEquals(Double.NaN, evaluation0.SFMeanSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.avgCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFMeasure(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, evaluation0.incorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedTruePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.errorRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.sizeOfPredictedRegions(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(1.0, evaluation0.kappa(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalsePositiveRate(), 0.01);
      assertEquals(Double.NaN, evaluation0.pctIncorrect(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedRecall(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedPrecision(), 0.01);
      assertEquals(0.0, evaluation0.totalCost(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.relativeAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.weightedFalseNegativeRate(), 0.01);
      assertEquals(1, SGDText.LOGLOSS);
      assertEquals(0, SGDText.HINGE);
      assertEquals((-2), TestInstances.NO_CLASS);
      assertEquals((-1), TestInstances.CLASS_IS_LAST);
      
      // Undeclared exception!
      try { 
        evaluation0.truePositiveRate(2);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 2
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test153()  throws Throwable  {
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      Capabilities capabilities0 = new Capabilities(inputMappedClassifier0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.numTruePositives(1);
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test154()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.numTruePositives((-1));
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test155()  throws Throwable  {
      Capabilities capabilities0 = new Capabilities((CapabilitiesHandler) null);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toClassDetailsString("");
      assertEquals("\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
  }

  @Test(timeout = 4000)
  public void test156()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toClassDetailsString("HE[");
      assertEquals("HE[\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
  }

  @Test(timeout = 4000)
  public void test157()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toSummaryString((String) null, false);
      assertEquals("null\nTotal Number of Instances                0     \n", string0);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test158()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFEntropyGain();
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test159()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFMeanSchemeEntropy();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test160()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFSchemeEntropy();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test161()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFMeanPriorEntropy();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test162()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.SFPriorEntropy();
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test163()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.KBInformation();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test164()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.relativeAbsoluteError();
      assertEquals(Double.NaN, evaluation0.meanAbsoluteError(), 0.01);
      assertEquals(Double.NaN, evaluation0.meanPriorAbsoluteError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test165()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.meanPriorAbsoluteError();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test166()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      double double0 = evaluation0.sizeOfPredictedRegions();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test167()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.coverageOfTestCasesByPredictedRegions();
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test168()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      DenseInstance denseInstance0 = new DenseInstance(1493);
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) simpleLinearRegression0, (Instance) denseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test169()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-2054.6752548), (int[]) null, 497);
      double[] doubleArray0 = new double[9];
      doubleArray0[0] = 3.0;
      try { 
        evaluation0.evaluationForSingleInstance(doubleArray0, binarySparseInstance0, true);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test170()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.weightedAreaUnderPRC();
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test171()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.areaUnderPRC(3264);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test172()  throws Throwable  {
      KernelEstimator kernelEstimator0 = new KernelEstimator((-1.0));
      Capabilities capabilities0 = new Capabilities(kernelEstimator0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.weightedAreaUnderROC();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test173()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.areaUnderROC(11);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test174()  throws Throwable  {
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      Capabilities capabilities0 = filteredClassifier0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.recall(2);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test175()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.meanAbsoluteError();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test176()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0, (CostMatrix) null);
      double double0 = evaluation0.rootMeanSquaredError();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test177()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.unclassified();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test178()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.correct();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test179()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      GaussianProcesses gaussianProcesses0 = new GaussianProcesses();
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(gaussianProcesses0, (Instance) null, 613.871754268414);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.functions.GaussianProcesses", e);
      }
  }

  @Test(timeout = 4000)
  public void test180()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setNumericPriorsFromBuffer();
      RegressionByDiscretization regressionByDiscretization0 = new RegressionByDiscretization();
      try { 
        evaluation0.updateStatsForConditionalDensityEstimator(regressionByDiscretization0, (Instance) null, 742.6219633921941);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.meta.RegressionByDiscretization", e);
      }
  }

  @Test(timeout = 4000)
  public void test181()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      int[] intArray0 = new int[5];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(4.0, intArray0, 1136903110);
      binarySparseInstance0.setDataset(instances0);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) 6;
      doubleArray0[1] = (double) 6;
      doubleArray0[2] = (double) (-726);
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(0.0, evaluation0.errorRate(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test182()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      int[] intArray0 = new int[5];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(4.0, intArray0, 1136903110);
      binarySparseInstance0.setDataset(instances0);
      double[] doubleArray0 = new double[5];
      doubleArray0[0] = (double) 6;
      doubleArray0[1] = (double) 6;
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test183()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      char[] charArray0 = new char[2];
      String string0 = evaluation0.num2ShortID(19, charArray0, 19);
      assertEquals("               \u0000\u0000\u0000\u0000", string0);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test184()  throws Throwable  {
      JRip jRip0 = new JRip();
      String string0 = Evaluation.makeOptionString(jRip0, true);
      assertNotNull(string0);
  }

  @Test(timeout = 4000)
  public void test185()  throws Throwable  {
      String string0 = Evaluation.makeOptionString((Classifier) null, true);
      assertNotNull(string0);
  }

  @Test(timeout = 4000)
  public void test186()  throws Throwable  {
      WrapperSubsetEval wrapperSubsetEval0 = new WrapperSubsetEval();
      Classifier classifier0 = wrapperSubsetEval0.getClassifier();
      String string0 = Evaluation.makeOptionString(classifier0, false);
      assertNotNull(string0);
  }

  @Test(timeout = 4000)
  public void test187()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      boolean boolean0 = evaluation0.equals(evaluation0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void test188()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Object object0 = new Object();
      boolean boolean0 = evaluation0.equals(object0);
      assertFalse(boolean0);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test189()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      boolean boolean0 = evaluation0.equals((Object) null);
      assertFalse(boolean0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test190()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      ConverterUtils.DataSource converterUtils_DataSource0 = new ConverterUtils.DataSource(instances0);
      Instance instance0 = converterUtils_DataSource0.nextElement(instances0);
      evaluation0.updatePriors(instance0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test191()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      ConverterUtils.DataSource converterUtils_DataSource0 = new ConverterUtils.DataSource(instances0);
      Instance instance0 = converterUtils_DataSource0.nextElement(instances0);
      evaluation0.updatePriors(instance0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test192()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      SparseInstance sparseInstance0 = new SparseInstance(15);
      instances0.add((Instance) sparseInstance0);
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test193()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.unweightedMicroFmeasure();
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test194()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.unweightedMacroFmeasure();
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test195()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.weightedFalseNegativeRate();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test196()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.falseNegativeRate(1);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test197()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.weightedTrueNegativeRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test198()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.trueNegativeRate((-5498));
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test199()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.toClassDetailsString("vY;Te%wK");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No per class statistics possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test200()  throws Throwable  {
      Capabilities capabilities0 = new Capabilities((CapabilitiesHandler) null);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toMatrixString(".bsi");
      assertEquals(".bsi\n a b   <-- classified as\n 0 0 | a = class1\n 0 0 | b = class2\n", string0);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test201()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.toMatrixString("");
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Evaluation: No confusion matrix possible!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test202()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.m_WithClass = 2005.24329;
      evaluation0.toSummaryString(" 0 OH*5X-(*U]Fj", false);
      assertEquals(0.0, evaluation0.pctIncorrect(), 0.01);
  }

  @Test(timeout = 4000)
  public void test203()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.toCumulativeMarginDistributionString();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Class must be nominal for margin distributions
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test204()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toCumulativeMarginDistributionString();
      assertEquals(" -1       0    \n", string0);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test205()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.KBMeanInformation();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute K&B Info score: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test206()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.KBInformation();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute K&B Info score: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test207()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.priorEntropy();
      assertEquals(1.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test208()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.priorEntropy();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute entropy of class prior: class numeric!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test209()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[3];
      LinearNNSearch linearNNSearch0 = new LinearNNSearch(instances0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      Instance instance0 = linearNNSearch0.nearestNeighbour(binarySparseInstance0);
      evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, instance0);
      double double0 = evaluation0.correlationCoefficient();
      assertEquals(0.5875000001862645, evaluation0.meanPriorAbsoluteError(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test210()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.correlationCoefficient();
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't compute correlation coefficient: class is nominal!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test211()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.correlationCoefficient();
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test212()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.kappa();
      assertEquals(1.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test213()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      Capabilities capabilities0 = new Capabilities(sGDText0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      CostMatrix costMatrix0 = new CostMatrix(2);
      Evaluation evaluation0 = new Evaluation(instances0, costMatrix0);
      double double0 = evaluation0.errorRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test214()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.errorRate();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFSchemeEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test215()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      InputMappedClassifier inputMappedClassifier0 = new InputMappedClassifier();
      double[] doubleArray0 = new double[0];
      DenseInstance denseInstance0 = new DenseInstance((-1), doubleArray0);
      try { 
        evaluation0.evaluationForSingleInstance((Classifier) inputMappedClassifier0, (Instance) denseInstance0, true);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.misc.InputMappedClassifier", e);
      }
  }

  @Test(timeout = 4000)
  public void test216()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      Vote vote0 = new Vote();
      DenseInstance denseInstance0 = new DenseInstance(5);
      try { 
        evaluation0.evaluateModelOnce((Classifier) vote0, (Instance) denseInstance0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // DenseInstance doesn't have access to a dataset!
         //
         verifyException("weka.core.AbstractInstance", e);
      }
  }

  @Test(timeout = 4000)
  public void test217()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance((-1), doubleArray0);
      binarySparseInstance0.setDataset(instances0);
      evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(-0.0, evaluation0.pctCorrect(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test218()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1);
      binarySparseInstance0.setDataset(instances0);
      evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      double double0 = evaluation0.relativeAbsoluteError();
      assertEquals(0.6125000005587935, evaluation0.rootMeanPriorSquaredError(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test219()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[3];
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(1, doubleArray0);
      binarySparseInstance0.setDataset(instances0);
      evaluation0.evaluateModelOnce((double) 6, (Instance) binarySparseInstance0);
      assertEquals(0.0, evaluation0.SFMeanPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test220()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[7];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      BinarySparseInstance binarySparseInstance0 = new BinarySparseInstance(sparseInstance0);
      binarySparseInstance0.setDataset(instances0);
      double double0 = evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) binarySparseInstance0);
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(0.0, evaluation0.numInstances(), 0.01);
  }

  @Test(timeout = 4000)
  public void test221()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      VotedPerceptron votedPerceptron0 = new VotedPerceptron();
      Object[] objectArray0 = new Object[0];
      evaluation0.evaluateModel((Classifier) votedPerceptron0, instances0, objectArray0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test222()  throws Throwable  {
      try { 
        Evaluation.handleCostOption("mW0", 106);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't open file null.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test223()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption("", 74);
      assertNull(costMatrix0);
  }

  @Test(timeout = 4000)
  public void test224()  throws Throwable  {
      CostMatrix costMatrix0 = Evaluation.handleCostOption((String) null, 74);
      assertNull(costMatrix0);
  }

  @Test(timeout = 4000)
  public void test225()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      AbstractClassifier.runClassifier(costSensitiveClassifier0, testInstances0.DEFAULT_WORDS);
      assertEquals(0, testInstances0.getNumRelationalString());
  }

  @Test(timeout = 4000)
  public void test226()  throws Throwable  {
      IBk iBk0 = new IBk();
      try { 
        Evaluation.evaluateModel((Classifier) iBk0, (String[]) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // 
         // Weka exception: null
         // 
         // General options:
         // 
         // -h or -help
         // \tOutput help information.
         // -synopsis or -info
         // \tOutput synopsis for classifier (use in conjunction  with -h)
         // -t <name of training file>
         // \tSets training file.
         // -T <name of test file>
         // \tSets test file. If missing, a cross-validation will be performed
         // \ton the training data.
         // -c <class index>
         // \tSets index of class attribute (default: last).
         // -x <number of folds>
         // \tSets number of folds for cross-validation (default: 10).
         // -no-cv
         // \tDo not perform any cross validation.
         // -split-percentage <percentage>
         // \tSets the percentage for the train/test set split, e.g., 66.
         // -preserve-order
         // \tPreserves the order in the percentage split.
         // -s <random number seed>
         // \tSets random number seed for cross-validation or percentage split
         // \t(default: 1).
         // -m <name of file with cost matrix>
         // \tSets file with cost matrix.
         // -l <name of input file>
         // \tSets model input file. In case the filename ends with '.xml',
         // \ta PMML file is loaded or, if that fails, options are loaded
         // \tfrom the XML file.
         // -d <name of output file>
         // \tSets model output file. In case the filename ends with '.xml',
         // \tonly the options are saved to the XML file, not the model.
         // -v
         // \tOutputs no statistics for training data.
         // -o
         // \tOutputs statistics only, not the classifier.
         // -i
         // \tOutputs detailed information-retrieval statistics for each class.
         // -k
         // \tOutputs information-theoretic statistics.
         // -classifications \"weka.classifiers.evaluation.output.prediction.AbstractOutput + options\"
         // \tUses the specified class for generating the classification output.
         // \tE.g.: weka.classifiers.evaluation.output.prediction.PlainText
         // -p range
         // \tOutputs predictions for test instances (or the train instances if
         // \tno test instances provided and -no-cv is used), along with the 
         // \tattributes in the specified range (and nothing else). 
         // \tUse '-p 0' if no attributes are desired.
         // \tDeprecated: use \"-classifications ...\" instead.
         // -distribution
         // \tOutputs the distribution instead of only the prediction
         // \tin conjunction with the '-p' option (only nominal classes).
         // \tDeprecated: use \"-classifications ...\" instead.
         // -r
         // \tOnly outputs cumulative margin distribution.
         // -xml filename | xml-string
         // \tRetrieves the options from the XML-data instead of the command line.
         // -threshold-file <file>
         // \tThe file to save the threshold data to.
         // \tThe format is determined by the extensions, e.g., '.arff' for ARFF 
         // \tformat or '.csv' for CSV.
         // -threshold-label <label>
         // \tThe class label to determine the threshold data for
         // \t(default is the first label)
         // 
         // Options specific to weka.classifiers.lazy.IBk:
         // 
         // -I
         // \tWeight neighbours by the inverse of their distance
         // \t(use when k > 1)
         // -F
         // \tWeight neighbours by 1 - their distance
         // \t(use when k > 1)
         // -K <number of neighbors>
         // \tNumber of nearest neighbours (k) used in classification.
         // \t(Default = 1)
         // -E
         // \tMinimise mean squared error rather than mean absolute
         // \terror when using -X option with numeric prediction.
         // -W <window size>
         // \tMaximum number of training instances maintained.
         // \tTraining instances are dropped FIFO. (Default = no window)
         // -X
         // \tSelect the number of nearest neighbours between 1
         // \tand the k value specified using hold-one-out evaluation
         // \ton the training data (use when k > 1)
         // -A
         // \tThe nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test227()  throws Throwable  {
      String[] stringArray0 = new String[0];
      Evaluation.main(stringArray0);
      assertEquals(0, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void test228()  throws Throwable  {
      String[] stringArray0 = new String[8];
      Evaluation.main(stringArray0);
      assertEquals(8, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void test229()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[][] doubleArray0 = evaluation0.confusionMatrix();
      assertEquals(2, doubleArray0.length);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test230()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setDiscardPredictions(true);
      assertTrue(evaluation0.getDiscardPredictions());
  }

  @Test(timeout = 4000)
  public void test231()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.setDiscardPredictions(false);
      assertFalse(evaluation0.getDiscardPredictions());
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test232()  throws Throwable  {
      SimpleLinearRegression simpleLinearRegression0 = new SimpleLinearRegression();
      Capabilities capabilities0 = simpleLinearRegression0.getCapabilities();
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate("weka/core/Capabilities.props");
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Throwable e) {
         //
         // Class has to be nominal if cost matrix given!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test233()  throws Throwable  {
      KernelEstimator kernelEstimator0 = new KernelEstimator((-1.0));
      Capabilities capabilities0 = new Capabilities(kernelEstimator0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      CostSensitiveClassifier costSensitiveClassifier0 = new CostSensitiveClassifier();
      CostMatrix costMatrix0 = costSensitiveClassifier0.getCostMatrix();
      Evaluation evaluation0 = null;
      try {
        evaluation0 = new Evaluation(instances0, costMatrix0);
        fail("Expecting exception: Exception");
      
      } catch(Throwable e) {
         //
         // Cost matrix not compatible with data!
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test234()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.avgCost();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertEquals(Double.NaN, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test235()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.getRevision();
      assertEquals("9101", string0);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test236()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[1];
      SparseInstance sparseInstance0 = new SparseInstance(0.0, doubleArray0);
      try { 
        evaluation0.evaluateModelOnce(Double.NaN, (Instance) sparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test237()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      boolean boolean0 = evaluation0.getDiscardPredictions();
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test238()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      try { 
        evaluation0.evaluateModelOnce((Classifier) null, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test239()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.getHeader();
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test240()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toSummaryString(false);
      assertEquals("=== Summary ===\n\nTotal Number of Instances                0     \n", string0);
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test241()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = evaluation0.getClassPriors();
      assertNotNull(doubleArray0);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0, doubleArray0.length);
  }

  @Test(timeout = 4000)
  public void test242()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toMatrixString();
      assertEquals("=== Confusion Matrix ===\n\n   <-- classified as\n", string0);
  }

  @Test(timeout = 4000)
  public void test243()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.m_WithClass = 2005.24329;
      evaluation0.toSummaryString(" 0 OH*5X-(*U]Fj", true);
      assertEquals(0.0, evaluation0.meanAbsoluteError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test244()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.pctUnclassified();
      assertEquals(Double.NaN, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test245()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      assertEquals(0.0, evaluation0.SFEntropyGain(), 0.01);
      
      evaluation0.useNoPriors();
      assertEquals(Double.NaN, evaluation0.SFEntropyGain(), 0.01);
  }

  @Test(timeout = 4000)
  public void test246()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.incorrect();
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test247()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toSummaryString();
      assertEquals(0.0, evaluation0.unclassified(), 0.01);
      assertEquals("\nTotal Number of Instances                0     \n", string0);
  }

  @Test(timeout = 4000)
  public void test248()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      evaluation0.rootRelativeSquaredError();
      assertEquals(Double.NaN, evaluation0.rootMeanSquaredError(), 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
      assertEquals(Double.NaN, evaluation0.rootMeanPriorSquaredError(), 0.01);
  }

  @Test(timeout = 4000)
  public void test249()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      String string0 = evaluation0.toClassDetailsString();
      assertEquals("=== Detailed Accuracy By Class ===\n\n                 TP Rate  FP Rate  Precision  Recall  F-Measure  MCC    ROC Area  PRC Area  Class\n                 0        0        0          0       0          0     ?         ?         class1\n                 0        0        0          0       0          0     ?         ?         class2\nWeighted Avg.  NaN      NaN      NaN        NaN     NaN        NaN    NaN       NaN    \n", string0);
      assertEquals(Double.NaN, evaluation0.unweightedMicroFmeasure(), 0.01);
  }

  @Test(timeout = 4000)
  public void test250()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.numInstances();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test251()  throws Throwable  {
      TestInstances testInstances0 = new TestInstances();
      Instances instances0 = testInstances0.generate("getMembershipValues");
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance((-11.0), doubleArray0);
      try { 
        evaluation0.evaluateModelOnce((double[]) null, (Instance) sparseInstance0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.Utils", e);
      }
  }

  @Test(timeout = 4000)
  public void test252()  throws Throwable  {
      AdaBoostM1 adaBoostM1_0 = new AdaBoostM1();
      try { 
        Evaluation.wekaStaticWrapper(adaBoostM1_0, (String) null);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // No model built yet
         //
         verifyException("weka.classifiers.meta.AdaBoostM1", e);
      }
  }

  @Test(timeout = 4000)
  public void test253()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      ZeroR zeroR0 = new ZeroR();
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction((Classifier) zeroR0, (Instance) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test254()  throws Throwable  {
      String[] stringArray0 = new String[0];
      try { 
        Evaluation.evaluateModel("L!{plZ/\"H[+", stringArray0);
        fail("Expecting exception: Exception");
      
      } catch(Exception e) {
         //
         // Can't find class with name L!{plZ/\"H[+.
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }

  @Test(timeout = 4000)
  public void test255()  throws Throwable  {
      KernelEstimator kernelEstimator0 = new KernelEstimator(9.487355874625381);
      Capabilities capabilities0 = new Capabilities(kernelEstimator0);
      TestInstances testInstances0 = TestInstances.forCapabilities(capabilities0);
      Instances instances0 = testInstances0.generate();
      Evaluation evaluation0 = new Evaluation(instances0);
      double double0 = evaluation0.totalCost();
      assertEquals(0.0, double0, 0.01);
      assertEquals(0.0, evaluation0.SFPriorEntropy(), 0.01);
  }

  @Test(timeout = 4000)
  public void test256()  throws Throwable  {
      TextDirectoryLoader textDirectoryLoader0 = new TextDirectoryLoader();
      Instances instances0 = textDirectoryLoader0.getDataSet();
      Evaluation evaluation0 = new Evaluation(instances0);
      double[] doubleArray0 = new double[0];
      SparseInstance sparseInstance0 = new SparseInstance(Double.NaN, doubleArray0);
      try { 
        evaluation0.evaluateModelOnceAndRecordPrediction(doubleArray0, (Instance) sparseInstance0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 0
         //
         verifyException("weka.classifiers.Evaluation", e);
      }
  }
}
